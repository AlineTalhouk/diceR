#' External validity indices
#' 
#' \strong{E}xternal \strong{v}alidity indices compare a predicted clustering 
#' result with a reference class or gold standard.
#' 
#' \code{ev_nmi} calculates the normalized mutual information
#' 
#' @param pred.lab predicted labels generated by classifier
#' @param ref.lab reference labels for the observations
#' @param method method of computing the entropy. Can be any one of "emp", "mm",
#'   "shrink", or "sg".
#'   
#' @return \code{ev_nmi} returns the normalized mutual information.
#' @references Strehl A, Ghosh J. Cluster ensembles: a knowledge reuse framework
#'   for combining multiple partitions. J. Mach. Learn. Res. 2002;3:583-617.
#' @note \code{ev_nmi} is adapted from \code{\link[infotheo]{mutinformation}}
#' @author Johnson Liu, Derek Chiu
#' @name external_validity
#' @export
#' 
#' @examples
#' set.seed(1)
#' E <- matrix(rep(sample(1:4, 1000, replace = TRUE)), nrow = 100, byrow =
#'               FALSE)
#' x <- sample(1:4, 100, replace = TRUE)
#' y <- sample(1:4, 100, replace = TRUE)
#' ev_nmi(x, y)
#' ev_confmat(x, y)
ev_nmi <- function(pred.lab, ref.lab, method = "emp") {
  U <- data.frame(ref.lab, pred.lab)
  Hyx <- infotheo::entropy(U, method)
  Hx <- infotheo::entropy(pred.lab, method)
  Hy <- infotheo::entropy(ref.lab, method)
  I <- ifelse(Hx + Hy - Hyx < 0, 0, Hx + Hy - Hyx)
  NMI <- I / sqrt(Hx * Hy)
  return(NMI)
}

#' @details \code{ev_confmat} calculates a variety of statistics associated
#' with confusion matrices.
#'
#' @return \code{ev_confmat} returns a vector of the following metrics: overall
#'   accuracy, Cohen's kappa, no information rate, accuracy p-value. Statistics
#'   are difficult to compare when there are multiclass comparisons. We hence 
#'   also report averaged statistics for: sensitivity, specificity, PPV, NPV,
#'   prevalence, detection rate, detection prevalence, accuracy, and balanced
#'   accuracy.
#' @rdname external_validity
#' @export
ev_confmat <- function(pred.lab, ref.lab) {
  if (!all(unique(pred.lab) %in% unique(ref.lab))) {
    stop("Error: Cluster labels should be the same in the prediction and reference classes.")
  }
  # Relabel predicted classes
  pred.relab <- relabel_class(pred.lab, ref.lab) %>% 
    factor(levels = sort(unique(ref.lab)))
  
  # Confusion matrix, column/row sums, total, true/false positives/negatives
  CM <- table(pred.relab, ref.lab)
  clm <- colSums(CM)
  rwm <- rowSums(CM)
  N <-  sum(CM)
  TP <- diag(CM)
  FP <- clm - TP
  FN <- rwm - TP
  TN <- N - (TP + FP + FN)
  
  # Overall confusion matrix statistics
  overall <- caret::confusionMatrix(pred.relab, ref.lab) %>%
    magrittr::use_series(overall) %>% 
    magrittr::extract(c("Accuracy", "Kappa", "AccuracyNull", "AccuracyPValue")) %>% 
    magrittr::set_names(c("Overall Accuracy", "Cohen's kappa",
                          "No Information Rate", "P-Value [Acc > NIR]"))
  
  # Combine with averaged statistics
  Sensitivity <- Specificity <- NULL
  result <- data.frame(TP, TN, clm, rwm) %>%
    dplyr::transmute(Sensitivity = TP / clm,
                     Specificity = TN / (N - clm),
                     PPV = TP / rwm,
                     NPV = TN / (N - rwm),
                     `Detection Rate` = TP / N,
                     Accuracy = (TP + TN) / N,
                     `Balanced Accuracy` = (Sensitivity + Specificity) / 2) %>% 
    magrittr::set_names(paste("Average", names(.))) %>% 
    colMeans() %>% 
    c(overall, .)
  return(result)
}