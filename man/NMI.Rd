% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stats.R
\name{NMI}
\alias{NMI}
\title{Normalized Mutual Information}
\usage{
NMI(X, Y, method = "emp")
}
\arguments{
\item{X}{clustering assignment}

\item{Y}{true class}

\item{method}{method of computing the entropy. Can be any one of "emp", "mm",
"shrink", or "sg".}
}
\value{
returns the normalized mutual information.
}
\description{
Computes the NMI given a clustering assignment and true class labels.
}
\details{
The function is adapted from the \code{mutinformation} function in the
\code{infotheo} package.
}
\examples{
set.seed(4)
X <- sample(1:4, 100, replace = TRUE)
Y <- sample(1:4, 100, replace = TRUE)
NMI(X, Y)
}
\author{
Derek Chiu
}
\references{
Strehl A, Ghosh J. Cluster ensembles: a knowledge reuse framework
  for combining multiple partitions. J. Mach. Learn. Res. 2002;3:583-617.
}

