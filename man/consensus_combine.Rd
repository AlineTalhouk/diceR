% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/consensus_combine.R, R/consensus_evaluate.R,
%   R/consensus_trim.R
\name{consensus_combine}
\alias{consensus_combine}
\alias{consensus_evaluate}
\alias{consensus_trim}
\title{Combine, evaluate, trim, and reweigh algorithms}
\usage{
consensus_combine(..., element = c("matrix", "class"))

consensus_evaluate(data, ..., cons.cl = NULL, ref.cl = NULL, plot = FALSE)

consensus_trim(data, ..., cons.cl = NULL, ref.cl = NULL, n = 5,
  reweigh = FALSE, show.eval = TRUE)
}
\arguments{
\item{...}{any number of objects outputted from
\code{\link{consensus_cluster}}}

\item{element}{either "matrix" or "class" to extract the consensus matrix or
consensus class, respectively.}

\item{data}{data matrix with rows as samples and columns as variables}

\item{cons.cl}{matrix of cluster assignments from consensus functions such
as \code{kmodes} and \code{majority_voting}}

\item{ref.cl}{reference class}

\item{plot}{logical; if \code{TRUE}, \code{graph_all} is called}

\item{n}{an integer specifying the top \code{n} algorithms to keep after 
trimming off the poor performing ones using Rank Aggregation. If the total
number of algorithms is less than \code{n} no trimming is done.}

\item{reweigh}{logical; if \code{TRUE}, after trimming out poor performing
algorithms, each algorithm is reweighed depending on its internal indices.}

\item{show.eval}{logical; if \code{TRUE} (default), show the evaluation 
output from \code{consensus_evaluate}}
}
\value{
\code{consensus_combine} returns either a list of all consensus
  matrices or a data frame showing all the consensus classes

\code{consensus_evaluate} returns a list with the following elements
  \item{k}{if \code{ref.cl} is not NULL, this is the number of distinct
  classes in the reference; otherwise the chosen \code{k} is determined by
  the one giving the largest mean PAC across algorithms}
  \item{pac}{a data frame showing the PAC for each combination of algorithm
  and cluster size}
  \item{internal}{a list of data frames for all k showing internal evaluation
  indices}
  \item{external}{a data frame showing external evaluation indices for
  \code{k}}

\code{consensus_trim} returns a list with three elements 
  \item{alg.keep}{algorithms kept}
  \item{alg.remove}{algorithms removed}
  \item{eval}{if \code{show.eval = TRUE}, the evaluation output is returned, 
  otherwise \code{NULL}}
  \item{data.new}{A new version of a \code{consensus_cluster} data object.
  Potentially no trimming depending on \code{n}}.
}
\description{
\code{consensus_combine} combines results for multiple objects from
\code{consensus_cluster()} and outputs either the consensus
matrices or consensus classes for all algorithms. \code{consensus_evaluate}
evaluates algorithms on internal/external validation indices.
\code{consensus_weigh} weighs clustering algorithms based on these two
indices. \code{consensus_trim} removes algorithms that rank low on internal
indices before using in consensus functions.
}
\details{
\code{consensus_combine} is useful for generating summaries because the
results have been combined into a single object. For example, if
\code{element = "class"}, then the resulting object can be used to create a
consensus matrix across algorithms, which can be visualized as a heatmap.

\code{consensus_evaluate} always shows internal indices. If \code{ref.cl} is
not \code{NULL}, external indices are shown in addition to internal indices.
Relevant graphical displays are also outputted.

\code{consensus_trim} ranks algorithms by internal indices used in
\code{consensus_evaluate}. The sum of the ranks for each algorithm is used as
the measure of comparison. This also means the magnitude of the internal
indices is not taken into account.
}
\examples{
# Consensus clustering for multiple algorithms
set.seed(911)
x <- matrix(rnorm(500), ncol = 10)
CC1 <- consensus_cluster(x, nk = 3:4, reps = 10, algorithms = "ap",
progress = FALSE)
CC2 <- consensus_cluster(x, nk = 3:4, reps = 10, algorithms = "gmm",
progress = FALSE)

# Combine and return either matrices or classes
y1 <- consensus_combine(CC1, CC2, element = "matrix")
str(y1)
y2 <- consensus_combine(CC1, CC2, element = "class")
str(y2)

# Evaluate algorithms on internal and external indices and make plots
set.seed(1)
ref.cl <- sample(1:4, 50, replace = TRUE)
z <- consensus_evaluate(x, CC1, CC2, ref.cl = ref.cl, plot = FALSE)

# Trim algorithms: remove those that rank low on internal indices
CC3 <- consensus_trim(x, CC1, CC2, ref.cl = ref.cl, n = 1)
str(CC3, max.level = 2)
}
\author{
Derek Chiu
}
